import requests
import json
import time
from datetime import datetime, timedelta
import hashlib
from typing import List, Dict

class ParisEventCollector:
    """Collecteur d'√©v√©nements culturels de Paris"""
    
    def __init__(self):
        # API officielle "Que Faire √† Paris"
        self.base_url = "https://opendata.paris.fr/api/records/1.0/search/"
        self.dataset = "que-faire-a-paris-"
        self.events = []
        
    def generate_hash(self, data: dict) -> str:
        """G√©n√®re un hash unique pour √©viter les doublons"""
        data_str = json.dumps(data, sort_keys=True)
        return hashlib.md5(data_str.encode()).hexdigest()
    
    def fetch_paris_events(self, max_events: int = 300) -> List[Dict]:
        """
        R√©cup√®re les √©v√©nements depuis l'API Paris Open Data
        
        Args:
            max_events: Nombre minimum d'√©v√©nements √† collecter
            
        Returns:
            Liste des √©v√©nements collect√©s
        """
        print(f"üóº Collecte des √©v√©nements de Paris...")
        print(f"üìä Objectif: {max_events} √©v√©nements minimum\n")
        
        collected = 0
        start = 0
        rows = 100  # Nombre d'√©v√©nements par requ√™te
        errors = 0
        
        while collected < max_events:
            try:
                print(f"üìÑ Requ√™te {start//rows + 1}...", end=" ")
                
                # Param√®tres de la requ√™te
                params = {
                    "dataset": "que-faire-a-paris-",
                    "rows": rows,
                    "start": start,
                    "sort": "date_start"
                }
                
                # Requ√™te avec timeout
                response = requests.get(
                    self.base_url,
                    params=params,
                    timeout=15
                )
                
                # V√©rification du statut
                if response.status_code != 200:
                    print(f"‚ùå Erreur {response.status_code}")
                    errors += 1
                    if errors > 3:
                        break
                    time.sleep(2)
                    continue
                
                data = response.json()
                
                # Extraction des √©v√©nements
                records = data.get("records", [])
                
                if not records:
                    print("‚ùå Plus d'√©v√©nements disponibles")
                    break
                
                # Traitement de chaque √©v√©nement
                for record in records:
                    # Extraction des champs pertinents
                    fields = record.get("fields", {})
                    
                    # Structure normalis√©e avec m√©tadonn√©es
                    event_document = {
                        "source": "paris_open_data",
                        "fetched_at": datetime.utcnow().isoformat() + "Z",
                        "raw_hash": self.generate_hash(fields),
                        "payload": {
                            "id": record.get("recordid"),
                            "title": fields.get("title"),
                            "description": fields.get("description"),
                            "category": fields.get("category"),
                            "tags": fields.get("tags", "").split(";") if fields.get("tags") else [],
                            "address": {
                                "street": fields.get("address_street"),
                                "zipcode": fields.get("address_zipcode"),
                                "city": fields.get("address_city", "Paris"),
                                "name": fields.get("address_name")
                            },
                            "location": fields.get("lat_lon"),
                            "dates": {
                                "start": fields.get("date_start"),
                                "end": fields.get("date_end"),
                                "description": fields.get("date_description")
                            },
                            "contact": {
                                "url": fields.get("contact_url"),
                                "phone": fields.get("contact_phone"),
                                "email": fields.get("contact_mail")
                            },
                            "price": {
                                "type": fields.get("price_type"),
                                "detail": fields.get("price_detail")
                            },
                            "accessibility": fields.get("access_type"),
                            "audience": fields.get("audience")
                        }
                    }
                    
                    self.events.append(event_document)
                    collected += 1
                
                print(f"‚úÖ {len(records)} √©v√©nements (Total: {collected})")
                
                # Pagination
                start += rows
                
                # Respect de l'API (rate limiting)
                time.sleep(0.3)
                
            except requests.exceptions.Timeout:
                print(f"‚è±Ô∏è Timeout")
                errors += 1
                if errors > 3:
                    print("\n‚ùå Trop d'erreurs, arr√™t de la collecte")
                    break
                time.sleep(2)
                    
            except requests.exceptions.RequestException as e:
                print(f"‚ùå Erreur r√©seau: {e}")
                errors += 1
                if errors > 3:
                    break
                time.sleep(2)
                
            except Exception as e:
                print(f"‚ùå Erreur inattendue: {e}")
                errors += 1
                if errors > 3:
                    break
        
        print(f"\n‚ú® Collecte termin√©e: {collected} √©v√©nements")
        print(f"‚ö†Ô∏è Erreurs rencontr√©es: {errors}")
        
        return self.events
    
    def save_to_json(self, filename: str = "events_raw.json"):
        """Sauvegarde les √©v√©nements dans un fichier JSON"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.events, f, ensure_ascii=False, indent=2)
        print(f"üíæ Donn√©es sauvegard√©es dans {filename}")
        
        # Sauvegarde d'un √©chantillon pour v√©rification
        if self.events:
            sample_file = "events_sample.json"
            with open(sample_file, 'w', encoding='utf-8') as f:
                json.dump(self.events[:5], f, ensure_ascii=False, indent=2)
            print(f"üìù √âchantillon sauvegard√© dans {sample_file}")
    
    def get_summary(self) -> Dict:
        """Retourne un r√©sum√© de la collecte"""
        if not self.events:
            return {"total": 0}
        
        # Extraction des cat√©gories
        categories = set()
        for event in self.events:
            cat = event["payload"].get("category")
            if cat:
                categories.add(cat)
        
        # Extraction des types de prix
        price_types = set()
        for event in self.events:
            price = event["payload"].get("price", {}).get("type")
            if price:
                price_types.add(price)
        
        return {
            "total_events": len(self.events),
            "sources": list(set(e["source"] for e in self.events)),
            "categories": list(categories),
            "price_types": list(price_types),
            "date_range": {
                "first_fetch": min(e["fetched_at"] for e in self.events),
                "last_fetch": max(e["fetched_at"] for e in self.events)
            }
        }


def main():
    """Point d'entr√©e principal"""
    print("=" * 70)
    print("üé™ COLLECTEUR D'√âV√âNEMENTS CULTURELS - PARIS OPEN DATA")
    print("=" * 70 + "\n")
    
    # Initialisation
    collector = ParisEventCollector()
    
    # Collecte
    events = collector.fetch_paris_events(max_events=300)
    
    # V√©rification
    if len(events) < 300:
        print(f"\n‚ö†Ô∏è Seulement {len(events)} √©v√©nements collect√©s")
        print("üí° Vous pouvez relancer avec une date diff√©rente ou ajouter d'autres villes")
    
    # Sauvegarde
    if events:
        collector.save_to_json()
        
        # R√©sum√© d√©taill√©
        print("\n" + "=" * 70)
        print("üìä R√âSUM√â DE LA COLLECTE")
        print("=" * 70)
        summary = collector.get_summary()
        print(f"\nüìà Total: {summary['total_events']} √©v√©nements")
        print(f"üè¢ Sources: {', '.join(summary['sources'])}")
        print(f"\nüé≠ Cat√©gories trouv√©es ({len(summary['categories'])}):")
        for cat in sorted(summary['categories'])[:10]:
            print(f"   ‚Ä¢ {cat}")
        if len(summary['categories']) > 10:
            print(f"   ... et {len(summary['categories']) - 10} autres")
        
        print(f"\nüí∞ Types de prix:")
        for price in summary['price_types']:
            print(f"   ‚Ä¢ {price}")
            
    else:
        print("\n‚ùå Aucun √©v√©nement collect√©")
        print("üí° V√©rifiez votre connexion internet")
    
    print("\n‚úÖ Script termin√©\n")


if __name__ == "__main__":
    main()